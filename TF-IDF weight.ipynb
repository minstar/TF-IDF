{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import nltk\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity\n",
    "def cosine_similarity(x, y):\n",
    "    x_sqrt = np.sqrt(np.dot(x, x))\n",
    "    y_sqrt = np.sqrt(np.dot(y, y))\n",
    "    if y_sqrt != 0:     \n",
    "        return (np.dot(x,y.T) / (x_sqrt * y_sqrt))\n",
    "    elif y_sqrt == 0:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.970725343394151\n"
     ]
    }
   ],
   "source": [
    "# check cosine_similarity\n",
    "print (cosine_similarity(np.array([1,2,3]), np.array([1,2,3])))\n",
    "print (cosine_similarity(np.array([3,4,5]), np.array([1,3,4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Inverted Index & Document Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(texts):\n",
    "    # input : string that needs to clean all number and signs\n",
    "\n",
    "    texts = re.sub('cnn',' cnn ', texts)\n",
    "    texts = re.sub('\\'', ' ', texts)\n",
    "    texts = ''.join(c for c in texts if c not in string.punctuation)\n",
    "    texts = ''.join([c for c in texts if not c.isdigit()])\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### doc2vocab ###\n",
    "# Doc 0 : (vocab 1 : num 1), (vocab 2 : num 2), (vocab 3 : num 3)\n",
    "# Doc 1 : ... \n",
    "\n",
    "### vocab2doc ###\n",
    "# word : [text_num1, text_num2 ... ]\n",
    "\n",
    "doc2vocab  = dict()\n",
    "vocab2doc  = dict()\n",
    "\n",
    "for i in range(0,60):\n",
    "    doc2vocab[i] = dict()\n",
    "\n",
    "    with open('./data/%d.txt' % i, 'r', encoding=\"utf-8\") as doc:\n",
    "        read_string = doc.read()                       # get sentence as read function\n",
    "        read_string = read_string.lower()              # sentence lower\n",
    "        read_string = clean_str(read_string)           # clean all punctuation and number\n",
    "        \n",
    "        tokens = nltk.word_tokenize(read_string)       # get tokens of sentence\n",
    "        stop = set(stopwords.words('english'))\n",
    "        tokens = [j for j in tokens if j not in stop] # get rid of stopwords at token\n",
    "        \n",
    "        ### get shape of {doc : {word1 : word1_num, word2 : word2_num, .... }}\n",
    "        for words in tokens:\n",
    "            # make document and vocab pair dictionary\n",
    "            if words in doc2vocab[i]:\n",
    "                doc2vocab[i][words] += 1\n",
    "                \n",
    "            else:\n",
    "                doc2vocab[i][words] = 1\n",
    "            \n",
    "            # make inverted index, {word : [doc1, doc3, ... ]}\n",
    "            text_str = str(i) + '.txt'\n",
    "            if words in vocab2doc:\n",
    "                if text_str not in vocab2doc[words]:\n",
    "                    vocab2doc[words].append(text_str)\n",
    "                    \n",
    "            else:\n",
    "                vocab2doc[words] = list()\n",
    "                vocab2doc[words].append(text_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Inverted Index 실행 결과 : president, obama 각각에 대한 list posting 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "president :  ['6.txt', '7.txt', '9.txt', '14.txt', '17.txt', '30.txt', '36.txt', '40.txt', '41.txt', '45.txt', '46.txt', '47.txt', '48.txt', '49.txt', '50.txt', '51.txt', '52.txt', '53.txt', '54.txt', '55.txt', '56.txt', '57.txt', '58.txt', '59.txt']\n",
      "obama :  ['6.txt', '36.txt', '40.txt', '41.txt', '43.txt', '44.txt', '46.txt', '47.txt', '48.txt', '49.txt', '50.txt', '53.txt', '54.txt', '57.txt', '58.txt']\n"
     ]
    }
   ],
   "source": [
    "# Inverted Index Posting Lists Result\n",
    "print ('president : ', vocab2doc['president'])\n",
    "print ('obama : ', vocab2doc['obama'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Term Frequency and Inverted Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnn</th>\n",
       "      <th>remember</th>\n",
       "      <th>miley</th>\n",
       "      <th>twerking</th>\n",
       "      <th>kanye</th>\n",
       "      <th>micsnatching</th>\n",
       "      <th>know</th>\n",
       "      <th>music</th>\n",
       "      <th>awards</th>\n",
       "      <th>get</th>\n",
       "      <th>...</th>\n",
       "      <th>centers</th>\n",
       "      <th>muchneeded</th>\n",
       "      <th>contact</th>\n",
       "      <th>homebound</th>\n",
       "      <th>ancillary</th>\n",
       "      <th>inperson</th>\n",
       "      <th>delivery</th>\n",
       "      <th>decreased</th>\n",
       "      <th>rate</th>\n",
       "      <th>falls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cnn  remember  miley  twerking  kanye  micsnatching  know  music  awards  \\\n",
       "0  1.0       1.0    1.0       1.0    2.0           1.0   1.0    7.0     2.0   \n",
       "1  1.0       0.0    0.0       0.0    1.0           0.0   0.0    0.0     0.0   \n",
       "2  1.0       0.0    0.0       0.0    0.0           0.0   0.0    0.0     0.0   \n",
       "3  1.0       0.0    0.0       0.0    0.0           0.0   0.0    0.0     0.0   \n",
       "4  1.0       0.0    0.0       0.0    0.0           0.0   0.0    0.0     0.0   \n",
       "\n",
       "   get  ...    centers  muchneeded  contact  homebound  ancillary  inperson  \\\n",
       "0  2.0  ...        0.0         0.0      0.0        0.0        0.0       0.0   \n",
       "1  0.0  ...        0.0         0.0      0.0        0.0        0.0       0.0   \n",
       "2  0.0  ...        0.0         0.0      0.0        0.0        0.0       0.0   \n",
       "3  1.0  ...        0.0         0.0      0.0        0.0        0.0       0.0   \n",
       "4  0.0  ...        0.0         0.0      0.0        0.0        0.0       0.0   \n",
       "\n",
       "   delivery  decreased  rate  falls  \n",
       "0       0.0        0.0   0.0    0.0  \n",
       "1       0.0        0.0   0.0    0.0  \n",
       "2       0.0        0.0   0.0    0.0  \n",
       "3       0.0        0.0   0.0    0.0  \n",
       "4       0.0        0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 6301 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_pd = pd.DataFrame.from_dict(doc2vocab, orient='index')\n",
    "term_pd = term_pd.fillna(0)\n",
    "term_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get query and Document TF-IDF weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get query from the query.txt\n",
    "query = list()\n",
    "\n",
    "f = open('./query.txt', 'r')\n",
    "query = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, time : 2.366121\n",
      "step : 10, time : 25.050186\n",
      "step : 20, time : 46.818120\n",
      "step : 30, time : 69.090080\n",
      "step : 40, time : 91.737705\n",
      "step : 50, time : 116.275198\n"
     ]
    }
   ],
   "source": [
    "def doc_tf_idf(dataframe, query):\n",
    "    \n",
    "    # query tf-idf\n",
    "    _, width = dataframe.shape\n",
    "    final = list()\n",
    "    \n",
    "    # document tf-idf \n",
    "    new_tf = dataframe\n",
    "    doc_term_value = dataframe[dataframe > 0].count().values # get array of number that document has that term\n",
    "    doc_frequency = np.log(60 / (doc_term_value + 1))\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(len(dataframe)):\n",
    "        results = np.zeros(width)\n",
    "        one_row = dataframe.loc[i]\n",
    "        row_value = one_row.values\n",
    "        row_index = one_row.index\n",
    "        \n",
    "        for j,term in enumerate(row_index):\n",
    "            if row_value[j] > 0:\n",
    "                #term_frequency = 1 + np.log(row_value[j])\n",
    "                term_frequency = np.log(row_value[j] + 1)\n",
    "                new_tf.iloc[i,j] = term_frequency * doc_frequency[j]\n",
    "                    \n",
    "            elif row_value[j] == 0:\n",
    "                term_frequency = 0\n",
    "                new_tf.iloc[i,j] = 0\n",
    "                \n",
    "            if term in query:\n",
    "                new_column = dataframe[[term]]\n",
    "                new_col_value = new_column[new_column > 0].count().values\n",
    "                results[j] = term_frequency * (np.log(60 / (new_col_value[0]+1)))\n",
    "        \n",
    "        final.append((i, cosine_similarity(new_tf.loc[i].values, results)))\n",
    "    \n",
    "        if i % 10 == 0:\n",
    "            print ('step : %d, time : %f' % (i, time.time()-start))\n",
    "            \n",
    "    return new_tf, final\n",
    "\n",
    "query_token = nltk.word_tokenize(query[0])\n",
    "term_doc_matrix, query_tf_idf = doc_tf_idf(term_pd, query_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) TF-IDF 실행결과 : president, obama를 포함한 term-document incidence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    president\n",
      "0    0.000000\n",
      "1    0.000000\n",
      "2    0.000000\n",
      "3    0.000000\n",
      "4    0.000000\n",
      "5    0.000000\n",
      "6    0.606829\n",
      "7    0.606829\n",
      "8    0.000000\n",
      "9    0.606829\n",
      "10   0.000000\n",
      "11   0.000000\n",
      "12   0.000000\n",
      "13   0.000000\n",
      "14   0.606829\n",
      "15   0.000000\n",
      "16   0.000000\n",
      "17   0.961801\n",
      "18   0.000000\n",
      "19   0.000000\n",
      "20   0.000000\n",
      "21   0.000000\n",
      "22   0.000000\n",
      "23   0.000000\n",
      "24   0.000000\n",
      "25   0.000000\n",
      "26   0.000000\n",
      "27   0.000000\n",
      "28   0.000000\n",
      "29   0.000000\n",
      "30   0.606829\n",
      "31   0.000000\n",
      "32   0.000000\n",
      "33   0.000000\n",
      "34   0.000000\n",
      "35   0.000000\n",
      "36   0.606829\n",
      "37   0.000000\n",
      "38   0.000000\n",
      "39   0.000000\n",
      "40   0.961801\n",
      "41   1.703584\n",
      "42   0.000000\n",
      "43   0.000000\n",
      "44   0.000000\n",
      "45   0.606829\n",
      "46   0.961801\n",
      "47   1.409013\n",
      "48   0.961801\n",
      "49   1.923601\n",
      "50   0.961801\n",
      "51   1.820486\n",
      "52   1.213657\n",
      "53   0.606829\n",
      "54   1.820486\n",
      "55   0.606829\n",
      "56   0.961801\n",
      "57   1.409013\n",
      "58   1.923601\n",
      "59   0.961801\n",
      "       obama\n",
      "0   0.000000\n",
      "1   0.000000\n",
      "2   0.000000\n",
      "3   0.000000\n",
      "4   0.000000\n",
      "5   0.000000\n",
      "6   2.127284\n",
      "7   0.000000\n",
      "8   0.000000\n",
      "9   0.000000\n",
      "10  0.000000\n",
      "11  0.000000\n",
      "12  0.000000\n",
      "13  0.000000\n",
      "14  0.000000\n",
      "15  0.000000\n",
      "16  0.000000\n",
      "17  0.000000\n",
      "18  0.000000\n",
      "19  0.000000\n",
      "20  0.000000\n",
      "21  0.000000\n",
      "22  0.000000\n",
      "23  0.000000\n",
      "24  0.000000\n",
      "25  0.000000\n",
      "26  0.000000\n",
      "27  0.000000\n",
      "28  0.000000\n",
      "29  0.000000\n",
      "30  0.000000\n",
      "31  0.000000\n",
      "32  0.000000\n",
      "33  0.000000\n",
      "34  0.000000\n",
      "35  0.000000\n",
      "36  0.916171\n",
      "37  0.000000\n",
      "38  0.000000\n",
      "39  0.000000\n",
      "40  0.916171\n",
      "41  1.452097\n",
      "42  0.000000\n",
      "43  1.452097\n",
      "44  2.748514\n",
      "45  0.000000\n",
      "46  2.904194\n",
      "47  3.169432\n",
      "48  2.127284\n",
      "49  1.452097\n",
      "50  2.572018\n",
      "51  0.000000\n",
      "52  0.000000\n",
      "53  1.832343\n",
      "54  1.832343\n",
      "55  0.000000\n",
      "56  0.000000\n",
      "57  0.916171\n",
      "58  0.916171\n",
      "59  0.000000\n"
     ]
    }
   ],
   "source": [
    "print (term_doc_matrix[['president']])\n",
    "print (term_doc_matrix[['obama']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Cosine-Similarity 실행결과 : president obama에 대한 Top 5 Document (Cosine-Similarity 결과값 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(54, 0.13070279880949837),\n",
       " (46, 0.09454470773792908),\n",
       " (58, 0.09291409102865486),\n",
       " (48, 0.07211185450587057),\n",
       " (50, 0.06748251115357565),\n",
       " (47, 0.06504438157882764),\n",
       " (55, 0.06370009984030921),\n",
       " (49, 0.06357678505803718),\n",
       " (6, 0.05875878994779375),\n",
       " (40, 0.058738137632291534),\n",
       " (43, 0.054313083339851576),\n",
       " (44, 0.05125329107048038),\n",
       " (41, 0.04133076142720179),\n",
       " (53, 0.04129233597173457),\n",
       " (56, 0.04037795307184632),\n",
       " (36, 0.039176545214350475),\n",
       " (45, 0.03710784434355158),\n",
       " (57, 0.03643747968883324),\n",
       " (51, 0.03573915479294042),\n",
       " (17, 0.03537844802603371),\n",
       " (14, 0.029618885627681935),\n",
       " (59, 0.026683852303785734),\n",
       " (7, 0.024671309354004366),\n",
       " (52, 0.023993171076371327),\n",
       " (30, 0.019608834011474948),\n",
       " (9, 0.013682777499492668),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (2, 0),\n",
       " (3, 0),\n",
       " (4, 0),\n",
       " (5, 0),\n",
       " (8, 0),\n",
       " (10, 0),\n",
       " (11, 0),\n",
       " (12, 0),\n",
       " (13, 0),\n",
       " (15, 0),\n",
       " (16, 0),\n",
       " (18, 0),\n",
       " (19, 0),\n",
       " (20, 0),\n",
       " (21, 0),\n",
       " (22, 0),\n",
       " (23, 0),\n",
       " (24, 0),\n",
       " (25, 0),\n",
       " (26, 0),\n",
       " (27, 0),\n",
       " (28, 0),\n",
       " (29, 0),\n",
       " (31, 0),\n",
       " (32, 0),\n",
       " (33, 0),\n",
       " (34, 0),\n",
       " (35, 0),\n",
       " (37, 0),\n",
       " (38, 0),\n",
       " (39, 0),\n",
       " (42, 0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Document number, Cosine-Similarity between query and document)\n",
    "score = sorted(query_tf_idf, key = lambda x : x[1], reverse=True)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
